{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e48829-c766-45a1-acb0-3252bc4f7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "import jax.numpy as np\n",
    "\n",
    "from optimize import *\n",
    "from regression import LogisticRegression\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192399f9-cb8a-4226-b7d2-053852555a85",
   "metadata": {},
   "source": [
    "# Plotting code\n",
    "\n",
    "Use the below function to show your line plots.\n",
    "\n",
    "`all_data` is expected to be a list of experiments, each experiment containing:\n",
    "1. \"train_loss\": the train loss at each step.\n",
    "2. \"label\": a label for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0563205-f4d1-4188-8093-e52faf71c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_superimposed_line_series(all_data, classification_problem):\n",
    "    for series in all_data:\n",
    "        plt.plot(series['validation_loss'], label = series['label'])   \n",
    "    #\n",
    "    plt.xlabel('Optimization step')\n",
    "    plt.ylabel('Validation NLL')\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.title('A comparison of stochastic gradient methods for '+classification_problem)\n",
    "    plt.legend()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3180466-ba89-4e72-b9c2-35a44fa0fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(X_train, Y_train, X_val, Y_val, label_0, label_1):\n",
    "    train_query = np.logical_or(Y_train==label_0, Y_train==label_1)\n",
    "    val_query = np.logical_or(Y_val==label_0, Y_val==label_1)\n",
    "\n",
    "    Y_train_query = Y_train[train_query]\n",
    "    Y_train_mapped = np.where(Y_train_query == label_0, np.zeros(Y_train_query.shape[0]), np.ones(Y_train_query.shape[0]))\n",
    "\n",
    "    Y_val_query = Y_val[val_query]\n",
    "    Y_val_mapped = np.where(Y_val_query == label_0, np.zeros(Y_val_query.shape[0]), np.ones(Y_val_query.shape[0]))\n",
    "\n",
    "    return X_train[train_query], Y_train_mapped, X_val[val_query], Y_val_mapped\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c79d5-09c2-492f-a818-09bc92099eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'\n",
    "X_train_all = np.load('X_'+dataset+'_train.npy')\n",
    "Y_train_all = np.load('Y_'+dataset+'_train.npy')\n",
    "X_val_all = np.load('X_'+dataset+'_val.npy')\n",
    "Y_val_all = np.load('Y_'+dataset+'_val.npy')\n",
    "\n",
    "cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "label_to_ind = dict([(cifar10_labels[i], i) for i in range(len(cifar10_labels))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a382b7-0cea-4e04-a3fc-ae08e62010a7",
   "metadata": {},
   "source": [
    "# The Superman split: birds vs. airplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280f4b4-5862-4330-a5ff-51eaff549807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's consider the Superman split: birds vs. airplanes\n",
    "X_train, Y_train, X_val, Y_val = gather_data(X_train_all, Y_train_all, X_val_all, Y_val_all, label_to_ind['bird'], label_to_ind['airplane'])\n",
    "\n",
    "N = X_train.shape[0]\n",
    "D = X_train.shape[1]\n",
    "\n",
    "# number of optimization steps\n",
    "T = 2**15\n",
    "\n",
    "# fix the seed\n",
    "seed = 0\n",
    "\n",
    "# run optimization below, with step sizes set to (L = Lipschitz constant):\n",
    "# * SGD (constant): step size is .2/L\n",
    "# * SGD (diminishing): starting step size is 2/L, ending step size is 1e-2/L\n",
    "# * SAGA (constant): step size is .1/L\n",
    "# * SGD w/ momentum (diminishing): starting step size is 2/L, ending step size is 1e-2/L\n",
    "\n",
    "lr = LogisticRegression(X_train, Y_train, X_val, Y_val, beta = 1e-1)\n",
    "\n",
    "init_prng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea2d49-410e-4163-bb09-b9d17702f38d",
   "metadata": {},
   "source": [
    "# Deer vs. horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb373008-04ef-4ae9-9180-abb20ce9a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will consider deers vs. horses\n",
    "X_train, Y_train, X_val, Y_val = gather_data(X_train_all, Y_train_all, X_val_all, Y_val_all, label_to_ind['deer'], label_to_ind['horse'])\n",
    "\n",
    "N = X_train.shape[0]\n",
    "D = X_train.shape[1]\n",
    "\n",
    "# number of optimization steps\n",
    "T = 2**15\n",
    "\n",
    "# fix the seed\n",
    "seed = 0\n",
    "\n",
    "# run optimization below, with step sizes set to (L = Lipschitz constant):\n",
    "# * SGD (constant): step size is .2/L\n",
    "# * SGD (diminishing): starting step size is 2/L, ending step size is 1e-2/L\n",
    "# * SAGA (constant): step size is .1/L\n",
    "# * SGD w/ momentum (diminishing): starting step size is 2/L, ending step size is 1e-2/L\n",
    "\n",
    "lr = LogisticRegression(X_train, Y_train, X_val, Y_val, beta = 1e-1)\n",
    "\n",
    "init_prng(seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
