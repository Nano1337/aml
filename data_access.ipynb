{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e48829-c766-45a1-acb0-3252bc4f7c11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "import jax.numpy as np\n",
    "\n",
    "from optimize import *\n",
    "from regression import LogisticRegression\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192399f9-cb8a-4226-b7d2-053852555a85",
   "metadata": {},
   "source": [
    "# Plotting code\n",
    "\n",
    "Use the below function to show your line plots.\n",
    "\n",
    "`all_data` is expected to be a list of experiments, each experiment containing:\n",
    "1. \"steps\": an array consisting of the number of data items accessed at each step.\n",
    "2. \"train_loss\": the train loss at each step.\n",
    "3. \"label\": a label for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0563205-f4d1-4188-8093-e52faf71c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_superimposed_line_series(all_data, classification_problem):\n",
    "    for series in all_data:\n",
    "        plt.plot(series['steps'], series['train_loss'], label = series['label'])   \n",
    "    #\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.xlabel('Number of data items accessed')\n",
    "    plt.ylabel('NLL')\n",
    "    plt.title('Performance as a function of data access for '+classification_problem)\n",
    "    plt.legend()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3180466-ba89-4e72-b9c2-35a44fa0fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(X_train, Y_train, X_val, Y_val, label_0, label_1):\n",
    "    train_query = np.logical_or(Y_train==label_0, Y_train==label_1)\n",
    "    val_query = np.logical_or(Y_val==label_0, Y_val==label_1)\n",
    "\n",
    "    Y_train_query = Y_train[train_query]\n",
    "    Y_train_mapped = np.where(Y_train_query == label_0, np.zeros(Y_train_query.shape[0]), np.ones(Y_train_query.shape[0]))\n",
    "\n",
    "    Y_val_query = Y_val[val_query]\n",
    "    Y_val_mapped = np.where(Y_val_query == label_0, np.zeros(Y_val_query.shape[0]), np.ones(Y_val_query.shape[0]))\n",
    "\n",
    "    return X_train[train_query], Y_train_mapped, X_val[val_query], Y_val_mapped\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945c79d5-09c2-492f-a818-09bc92099eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'\n",
    "X_train_all = np.load('X_'+dataset+'_train.npy')\n",
    "Y_train_all = np.load('Y_'+dataset+'_train.npy')\n",
    "X_val_all = np.load('X_'+dataset+'_val.npy')\n",
    "Y_val_all = np.load('Y_'+dataset+'_val.npy')\n",
    "\n",
    "cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "label_to_ind = dict([(cifar10_labels[i], i) for i in range(len(cifar10_labels))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a382b7-0cea-4e04-a3fc-ae08e62010a7",
   "metadata": {},
   "source": [
    "# The Superman split: birds vs. airplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280f4b4-5862-4330-a5ff-51eaff549807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's consider the Superman split: birds vs. airplanes\n",
    "X_train, Y_train, X_val, Y_val = gather_data(X_train_all, Y_train_all, X_val_all, Y_val_all, label_to_ind['bird'], label_to_ind['airplane'])\n",
    "\n",
    "N = X_train.shape[0]\n",
    "D = X_train.shape[1]\n",
    "\n",
    "# total number of data items to access: 2^15\n",
    "total_data_items = 2**15\n",
    "\n",
    "# for GD and Newton's method, we require the training data size\n",
    "T_batch = math.ceil(total_data_items / N)\n",
    "\n",
    "# for SGD and minibatch methods\n",
    "T_1 = total_data_items\n",
    "T_8 = total_data_items // 8\n",
    "T_32 = total_data_items // 32\n",
    "\n",
    "# fix the seed\n",
    "seed = 0\n",
    "\n",
    "# run optimization below, with step sizes set to (L = Lipschitz constant):\n",
    "# * GD: 2/L\n",
    "# * Newton: 0.5\n",
    "# * Minibatch & SGD: starting step size is 2/L, ending step size is 1e-2/L\n",
    "\n",
    "lr = LogisticRegression(X_train, Y_train, X_val, Y_val, beta = 1e-1)\n",
    "\n",
    "init_prng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea2d49-410e-4163-bb09-b9d17702f38d",
   "metadata": {},
   "source": [
    "# Deer vs. horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb373008-04ef-4ae9-9180-abb20ce9a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will consider deers vs. horses\n",
    "X_train, Y_train, X_val, Y_val = gather_data(X_train_all, Y_train_all, X_val_all, Y_val_all, label_to_ind['deer'], label_to_ind['horse'])\n",
    "\n",
    "N = X_train.shape[0]\n",
    "D = X_train.shape[1]\n",
    "\n",
    "# total number of data items to access: 2^15\n",
    "total_data_items = 2**15\n",
    "\n",
    "# for GD and Newton's method, we require the training data size\n",
    "T_batch = math.ceil(total_data_items / N)\n",
    "\n",
    "# for SGD and minibatch methods\n",
    "T_1 = total_data_items\n",
    "T_8 = total_data_items // 8\n",
    "T_32 = total_data_items // 32\n",
    "\n",
    "# fix the seed\n",
    "seed = 0\n",
    "\n",
    "# run optimization below, with step sizes set to (L = Lipschitz constant):\n",
    "# * GD: 2/L\n",
    "# * Newton: .5\n",
    "# * Minibatch & SGD: starting step size is 2/L, ending step size is 1e-2/L\n",
    "\n",
    "lr = LogisticRegression(X_train, Y_train, X_val, Y_val, beta = 1e-1)\n",
    "\n",
    "init_prng(seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
